{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7bdc1de4-21f5-40d7-a918-75fb352de426",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from modules import * \n",
    "#contains functions used in common with processing election and IRS data\n",
    "\n",
    "import os #Used when reading/writing csv files programatically"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cf8ba2dc-2b6e-4dcd-aff5-c132bea9c75f",
   "metadata": {},
   "outputs": [],
   "source": [
    "irs_folder_path = '../data/irs_data/'\n",
    "\n",
    "irs_files = [file for file in os.listdir(irs_folder_path) if os.path.isfile(os.path.join(irs_folder_path, file)) and file.endswith('f_d.csv')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f5ed7448-c4d5-47e9-ae58-9fbb17429700",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['irs_count_2012_f_d.csv',\n",
       " 'irs_count_2014_f_d.csv',\n",
       " 'irs_count_2016_f_d.csv',\n",
       " 'irs_count_2018_f_d.csv',\n",
       " 'irs_count_2020_f_d.csv']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "irs_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2d3d555c-6257-406d-9a9c-1e78e5410fb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged = pd.DataFrame()\n",
    "for i in irs_files:\n",
    "    df = pd.read_csv(irs_folder_path + i)\n",
    "    merged = pd.concat([merged, df], ignore_index=True)\n",
    "\n",
    "# Optionally, you may want to reset the index of the merged DataFrame\n",
    "merged.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3623cfdd-29b1-4bc6-a47c-83348a53d324",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STATE             5\n",
      "COUNTYNAME        5\n",
      "N1                8\n",
      "MARS1             8\n",
      "MARS2             8\n",
      "              ...  \n",
      "A10970        12613\n",
      "N10971        12613\n",
      "A10971        12613\n",
      "N10973        12613\n",
      "A10973        12613\n",
      "Length: 179, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(merged.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4d9deceb-b2b0-41a9-9387-565600b268a4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>STATE</th>\n",
       "      <th>COUNTYNAME</th>\n",
       "      <th>N1</th>\n",
       "      <th>MARS1</th>\n",
       "      <th>MARS2</th>\n",
       "      <th>MARS4</th>\n",
       "      <th>PREP</th>\n",
       "      <th>N2</th>\n",
       "      <th>NUMDEP</th>\n",
       "      <th>A00100</th>\n",
       "      <th>...</th>\n",
       "      <th>N02910</th>\n",
       "      <th>A02910</th>\n",
       "      <th>N11450</th>\n",
       "      <th>A11450</th>\n",
       "      <th>N10970</th>\n",
       "      <th>A10970</th>\n",
       "      <th>N10971</th>\n",
       "      <th>A10971</th>\n",
       "      <th>N10973</th>\n",
       "      <th>A10973</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6114</th>\n",
       "      <td>WA</td>\n",
       "      <td>adams county</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6209</th>\n",
       "      <td>WI</td>\n",
       "      <td>adams county</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6281</th>\n",
       "      <td>WY</td>\n",
       "      <td>albany county</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6304</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6305</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6306</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6307</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6308</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 179 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     STATE     COUNTYNAME  N1  MARS1  MARS2  MARS4  PREP  N2  NUMDEP  A00100  \\\n",
       "6114    WA   adams county NaN    NaN    NaN    NaN   NaN NaN     NaN     NaN   \n",
       "6209    WI   adams county NaN    NaN    NaN    NaN   NaN NaN     NaN     NaN   \n",
       "6281    WY  albany county NaN    NaN    NaN    NaN   NaN NaN     NaN     NaN   \n",
       "6304   NaN            NaN NaN    NaN    NaN    NaN   NaN NaN     NaN     NaN   \n",
       "6305   NaN            NaN NaN    NaN    NaN    NaN   NaN NaN     NaN     NaN   \n",
       "6306   NaN            NaN NaN    NaN    NaN    NaN   NaN NaN     NaN     NaN   \n",
       "6307   NaN            NaN NaN    NaN    NaN    NaN   NaN NaN     NaN     NaN   \n",
       "6308   NaN            NaN NaN    NaN    NaN    NaN   NaN NaN     NaN     NaN   \n",
       "\n",
       "      ...  N02910  A02910  N11450  A11450  N10970  A10970  N10971  A10971  \\\n",
       "6114  ...     NaN     NaN     NaN     NaN     NaN     NaN     NaN     NaN   \n",
       "6209  ...     NaN     NaN     NaN     NaN     NaN     NaN     NaN     NaN   \n",
       "6281  ...     NaN     NaN     NaN     NaN     NaN     NaN     NaN     NaN   \n",
       "6304  ...     NaN     NaN     NaN     NaN     NaN     NaN     NaN     NaN   \n",
       "6305  ...     NaN     NaN     NaN     NaN     NaN     NaN     NaN     NaN   \n",
       "6306  ...     NaN     NaN     NaN     NaN     NaN     NaN     NaN     NaN   \n",
       "6307  ...     NaN     NaN     NaN     NaN     NaN     NaN     NaN     NaN   \n",
       "6308  ...     NaN     NaN     NaN     NaN     NaN     NaN     NaN     NaN   \n",
       "\n",
       "      N10973  A10973  \n",
       "6114     NaN     NaN  \n",
       "6209     NaN     NaN  \n",
       "6281     NaN     NaN  \n",
       "6304     NaN     NaN  \n",
       "6305     NaN     NaN  \n",
       "6306     NaN     NaN  \n",
       "6307     NaN     NaN  \n",
       "6308     NaN     NaN  \n",
       "\n",
       "[8 rows x 179 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged.loc[merged['N1'].isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b12a2e71-8536-449f-80f2-f4abda9cfb9a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "irs_raw_folder_path = '../data/irs_data/raw' \n",
    "irs_folder_path = '../data/irs_data/'\n",
    "\n",
    "irs_raw_files = [file for file in os.listdir(irs_raw_folder_path ) if os.path.isfile(os.path.join(irs_raw_folder_path , file))]\n",
    "\n",
    "# reverse the order, so the newest data is at the front of this list \n",
    "# No real need for this, but it helps with thinking about the values we're examining\n",
    "# We want growth to be positive and loss to be negative to keep with the common understanding\n",
    "irs_raw_files = irs_raw_files[::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "57928bc8-b05e-43a9-b980-42dca7361571",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Formatting raw IRS data\n"
     ]
    }
   ],
   "source": [
    "# Create empty list to hold tuples of filenames|dataframes\n",
    "processed_irs_files = []\n",
    "\n",
    "print(\"Formatting raw IRS data\")\n",
    "for i in irs_raw_files:\n",
    "    file = pd.read_csv(f'{irs_raw_folder_path}/{i}', encoding='latin-1') #irs formatting requires this encoding\n",
    "    file = file.drop(['STATEFIPS','AGI_STUB','COUNTYFIPS'],axis=1).reset_index(drop=True) # drop columns not used for the current analysis, but raw files are presevered for future use.\n",
    "    \n",
    "    # Lambda function to generate a boolian mask filtering 'COUNTYNAME' values with a single word, \n",
    "    # removing all single name counties (should be agg. state data)\n",
    "    filter_counties = lambda row: len(row['COUNTYNAME'].split()) >=2\n",
    "    data_counties = file[file.apply(filter_counties, axis=1)]\n",
    "    lower_countynames = [' '.join(i.split()[:-1]).lower() for i in data_counties['COUNTYNAME']]\n",
    "    data_copy = data_counties.copy()\n",
    "    data_copy['COUNTYNAME'] = lower_countynames\n",
    "    \n",
    "    # Generate a name for each dataframe based on the filename without the file extension\n",
    "    name = f'{i}' \n",
    "    name = name[:-4]+'_f' \n",
    "    \n",
    "    # Assign the dataframe to the variable name\n",
    "    # globals()[name] = data_copy # from the documentation: 'the globals() function is a built-in function that returns a dictionary representing the current global symbol table' only half understand this, but it works (#programming)\n",
    "    \n",
    "    # Append both to the empty list\n",
    "    processed_irs_files.append((name, data_copy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a9a28738-5fa0-4e1f-a69e-ed9764b24977",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>STATE</th>\n",
       "      <th>COUNTYNAME</th>\n",
       "      <th>N1</th>\n",
       "      <th>MARS1</th>\n",
       "      <th>MARS2</th>\n",
       "      <th>MARS4</th>\n",
       "      <th>ELF</th>\n",
       "      <th>CPREP</th>\n",
       "      <th>PREP</th>\n",
       "      <th>DIR_DEP</th>\n",
       "      <th>...</th>\n",
       "      <th>N85300</th>\n",
       "      <th>A85300</th>\n",
       "      <th>N11901</th>\n",
       "      <th>A11901</th>\n",
       "      <th>N11900</th>\n",
       "      <th>A11900</th>\n",
       "      <th>N11902</th>\n",
       "      <th>A11902</th>\n",
       "      <th>N12000</th>\n",
       "      <th>A12000</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AL</td>\n",
       "      <td>autauga</td>\n",
       "      <td>26320.0</td>\n",
       "      <td>11410.0</td>\n",
       "      <td>10130.0</td>\n",
       "      <td>4100.0</td>\n",
       "      <td>24310.0</td>\n",
       "      <td>700.0</td>\n",
       "      <td>11760.0</td>\n",
       "      <td>19040.0</td>\n",
       "      <td>...</td>\n",
       "      <td>290.0</td>\n",
       "      <td>604.0</td>\n",
       "      <td>5020.0</td>\n",
       "      <td>19136.0</td>\n",
       "      <td>20570.0</td>\n",
       "      <td>64502.0</td>\n",
       "      <td>20310.0</td>\n",
       "      <td>60927.0</td>\n",
       "      <td>340.0</td>\n",
       "      <td>3181.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AL</td>\n",
       "      <td>baldwin</td>\n",
       "      <td>112470.0</td>\n",
       "      <td>49740.0</td>\n",
       "      <td>46300.0</td>\n",
       "      <td>13310.0</td>\n",
       "      <td>102570.0</td>\n",
       "      <td>3060.0</td>\n",
       "      <td>55050.0</td>\n",
       "      <td>73130.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3070.0</td>\n",
       "      <td>10401.0</td>\n",
       "      <td>24830.0</td>\n",
       "      <td>157074.0</td>\n",
       "      <td>82860.0</td>\n",
       "      <td>293170.0</td>\n",
       "      <td>79960.0</td>\n",
       "      <td>247067.0</td>\n",
       "      <td>3810.0</td>\n",
       "      <td>45965.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AL</td>\n",
       "      <td>barbour</td>\n",
       "      <td>10760.0</td>\n",
       "      <td>5490.0</td>\n",
       "      <td>2790.0</td>\n",
       "      <td>2270.0</td>\n",
       "      <td>9340.0</td>\n",
       "      <td>250.0</td>\n",
       "      <td>6410.0</td>\n",
       "      <td>6810.0</td>\n",
       "      <td>...</td>\n",
       "      <td>100.0</td>\n",
       "      <td>273.0</td>\n",
       "      <td>1480.0</td>\n",
       "      <td>6578.0</td>\n",
       "      <td>8510.0</td>\n",
       "      <td>27152.0</td>\n",
       "      <td>8410.0</td>\n",
       "      <td>26521.0</td>\n",
       "      <td>140.0</td>\n",
       "      <td>529.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AL</td>\n",
       "      <td>bibb</td>\n",
       "      <td>9330.0</td>\n",
       "      <td>4440.0</td>\n",
       "      <td>3170.0</td>\n",
       "      <td>1550.0</td>\n",
       "      <td>8180.0</td>\n",
       "      <td>250.0</td>\n",
       "      <td>4720.0</td>\n",
       "      <td>6490.0</td>\n",
       "      <td>...</td>\n",
       "      <td>50.0</td>\n",
       "      <td>124.0</td>\n",
       "      <td>1310.0</td>\n",
       "      <td>3650.0</td>\n",
       "      <td>7620.0</td>\n",
       "      <td>23846.0</td>\n",
       "      <td>7560.0</td>\n",
       "      <td>22534.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>1194.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>AL</td>\n",
       "      <td>blount</td>\n",
       "      <td>24670.0</td>\n",
       "      <td>10120.0</td>\n",
       "      <td>11400.0</td>\n",
       "      <td>2630.0</td>\n",
       "      <td>23210.0</td>\n",
       "      <td>530.0</td>\n",
       "      <td>14920.0</td>\n",
       "      <td>18100.0</td>\n",
       "      <td>...</td>\n",
       "      <td>190.0</td>\n",
       "      <td>357.0</td>\n",
       "      <td>4130.0</td>\n",
       "      <td>16496.0</td>\n",
       "      <td>19730.0</td>\n",
       "      <td>60471.0</td>\n",
       "      <td>19480.0</td>\n",
       "      <td>57848.0</td>\n",
       "      <td>340.0</td>\n",
       "      <td>2522.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3188</th>\n",
       "      <td>WY</td>\n",
       "      <td>sweetwater</td>\n",
       "      <td>19850.0</td>\n",
       "      <td>9070.0</td>\n",
       "      <td>8110.0</td>\n",
       "      <td>2320.0</td>\n",
       "      <td>18770.0</td>\n",
       "      <td>460.0</td>\n",
       "      <td>9440.0</td>\n",
       "      <td>14510.0</td>\n",
       "      <td>...</td>\n",
       "      <td>330.0</td>\n",
       "      <td>684.0</td>\n",
       "      <td>3030.0</td>\n",
       "      <td>13647.0</td>\n",
       "      <td>16320.0</td>\n",
       "      <td>56128.0</td>\n",
       "      <td>16020.0</td>\n",
       "      <td>52219.0</td>\n",
       "      <td>430.0</td>\n",
       "      <td>3431.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3189</th>\n",
       "      <td>WY</td>\n",
       "      <td>teton</td>\n",
       "      <td>15130.0</td>\n",
       "      <td>8940.0</td>\n",
       "      <td>4910.0</td>\n",
       "      <td>930.0</td>\n",
       "      <td>14080.0</td>\n",
       "      <td>340.0</td>\n",
       "      <td>8770.0</td>\n",
       "      <td>7740.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1910.0</td>\n",
       "      <td>136918.0</td>\n",
       "      <td>4260.0</td>\n",
       "      <td>109426.0</td>\n",
       "      <td>10420.0</td>\n",
       "      <td>271359.0</td>\n",
       "      <td>8820.0</td>\n",
       "      <td>60800.0</td>\n",
       "      <td>1960.0</td>\n",
       "      <td>207001.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3190</th>\n",
       "      <td>WY</td>\n",
       "      <td>uinta</td>\n",
       "      <td>9510.0</td>\n",
       "      <td>4040.0</td>\n",
       "      <td>4320.0</td>\n",
       "      <td>990.0</td>\n",
       "      <td>8930.0</td>\n",
       "      <td>230.0</td>\n",
       "      <td>4640.0</td>\n",
       "      <td>6810.0</td>\n",
       "      <td>...</td>\n",
       "      <td>130.0</td>\n",
       "      <td>441.0</td>\n",
       "      <td>1570.0</td>\n",
       "      <td>7215.0</td>\n",
       "      <td>7640.0</td>\n",
       "      <td>27463.0</td>\n",
       "      <td>7500.0</td>\n",
       "      <td>24596.0</td>\n",
       "      <td>200.0</td>\n",
       "      <td>2597.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3191</th>\n",
       "      <td>WY</td>\n",
       "      <td>washakie</td>\n",
       "      <td>3790.0</td>\n",
       "      <td>1700.0</td>\n",
       "      <td>1680.0</td>\n",
       "      <td>330.0</td>\n",
       "      <td>3540.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>1980.0</td>\n",
       "      <td>2550.0</td>\n",
       "      <td>...</td>\n",
       "      <td>50.0</td>\n",
       "      <td>303.0</td>\n",
       "      <td>710.0</td>\n",
       "      <td>4081.0</td>\n",
       "      <td>2900.0</td>\n",
       "      <td>8495.0</td>\n",
       "      <td>2800.0</td>\n",
       "      <td>7769.0</td>\n",
       "      <td>140.0</td>\n",
       "      <td>594.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3192</th>\n",
       "      <td>WY</td>\n",
       "      <td>weston</td>\n",
       "      <td>3300.0</td>\n",
       "      <td>1510.0</td>\n",
       "      <td>1480.0</td>\n",
       "      <td>260.0</td>\n",
       "      <td>3060.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>1980.0</td>\n",
       "      <td>2090.0</td>\n",
       "      <td>...</td>\n",
       "      <td>50.0</td>\n",
       "      <td>115.0</td>\n",
       "      <td>640.0</td>\n",
       "      <td>2729.0</td>\n",
       "      <td>2490.0</td>\n",
       "      <td>7972.0</td>\n",
       "      <td>2380.0</td>\n",
       "      <td>7153.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>631.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3153 rows × 163 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     STATE  COUNTYNAME        N1    MARS1    MARS2    MARS4       ELF   CPREP  \\\n",
       "1       AL     autauga   26320.0  11410.0  10130.0   4100.0   24310.0   700.0   \n",
       "2       AL     baldwin  112470.0  49740.0  46300.0  13310.0  102570.0  3060.0   \n",
       "3       AL     barbour   10760.0   5490.0   2790.0   2270.0    9340.0   250.0   \n",
       "4       AL        bibb    9330.0   4440.0   3170.0   1550.0    8180.0   250.0   \n",
       "5       AL      blount   24670.0  10120.0  11400.0   2630.0   23210.0   530.0   \n",
       "...    ...         ...       ...      ...      ...      ...       ...     ...   \n",
       "3188    WY  sweetwater   19850.0   9070.0   8110.0   2320.0   18770.0   460.0   \n",
       "3189    WY       teton   15130.0   8940.0   4910.0    930.0   14080.0   340.0   \n",
       "3190    WY       uinta    9510.0   4040.0   4320.0    990.0    8930.0   230.0   \n",
       "3191    WY    washakie    3790.0   1700.0   1680.0    330.0    3540.0    80.0   \n",
       "3192    WY      weston    3300.0   1510.0   1480.0    260.0    3060.0    40.0   \n",
       "\n",
       "         PREP  DIR_DEP  ...  N85300    A85300   N11901    A11901   N11900  \\\n",
       "1     11760.0  19040.0  ...   290.0     604.0   5020.0   19136.0  20570.0   \n",
       "2     55050.0  73130.0  ...  3070.0   10401.0  24830.0  157074.0  82860.0   \n",
       "3      6410.0   6810.0  ...   100.0     273.0   1480.0    6578.0   8510.0   \n",
       "4      4720.0   6490.0  ...    50.0     124.0   1310.0    3650.0   7620.0   \n",
       "5     14920.0  18100.0  ...   190.0     357.0   4130.0   16496.0  19730.0   \n",
       "...       ...      ...  ...     ...       ...      ...       ...      ...   \n",
       "3188   9440.0  14510.0  ...   330.0     684.0   3030.0   13647.0  16320.0   \n",
       "3189   8770.0   7740.0  ...  1910.0  136918.0   4260.0  109426.0  10420.0   \n",
       "3190   4640.0   6810.0  ...   130.0     441.0   1570.0    7215.0   7640.0   \n",
       "3191   1980.0   2550.0  ...    50.0     303.0    710.0    4081.0   2900.0   \n",
       "3192   1980.0   2090.0  ...    50.0     115.0    640.0    2729.0   2490.0   \n",
       "\n",
       "        A11900   N11902    A11902  N12000    A12000  \n",
       "1      64502.0  20310.0   60927.0   340.0    3181.0  \n",
       "2     293170.0  79960.0  247067.0  3810.0   45965.0  \n",
       "3      27152.0   8410.0   26521.0   140.0     529.0  \n",
       "4      23846.0   7560.0   22534.0    90.0    1194.0  \n",
       "5      60471.0  19480.0   57848.0   340.0    2522.0  \n",
       "...        ...      ...       ...     ...       ...  \n",
       "3188   56128.0  16020.0   52219.0   430.0    3431.0  \n",
       "3189  271359.0   8820.0   60800.0  1960.0  207001.0  \n",
       "3190   27463.0   7500.0   24596.0   200.0    2597.0  \n",
       "3191    8495.0   2800.0    7769.0   140.0     594.0  \n",
       "3192    7972.0   2380.0    7153.0   120.0     631.0  \n",
       "\n",
       "[3153 rows x 163 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_irs_files[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5e786e4f-26cc-41e7-a646-392b90b834d2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# for i in processed_irs_files:\n",
    "#     print(i[1].loc[i[1]['N1'].isna()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e903d8c2-e1c4-47ab-a719-b8c499ac9ad8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading IRS data\n"
     ]
    }
   ],
   "source": [
    "# Read IRS data\n",
    "print(\"Reading IRS data\")\n",
    "\n",
    "irs_raw_folder_path = '../data/irs_data/raw' \n",
    "irs_folder_path = '../data/irs_data/'\n",
    "\n",
    "irs_raw_files = [file for file in os.listdir(irs_raw_folder_path ) if os.path.isfile(os.path.join(irs_raw_folder_path , file))]\n",
    "\n",
    "# reverse the order, so the newest data is at the front of this list \n",
    "# No real need for this, but it helps with thinking about the values we're examining\n",
    "# We want growth to be positive and loss to be negative to keep with the common understanding\n",
    "irs_raw_files = irs_raw_files[::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "beecea85-c51a-46f6-9614-a203b37f828b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Formatting raw IRS data\n"
     ]
    }
   ],
   "source": [
    "# Create empty list to hold tuples of filenames|dataframes\n",
    "processed_irs_files = []\n",
    "\n",
    "print(\"Formatting raw IRS data\")\n",
    "for i in irs_raw_files:\n",
    "    file = pd.read_csv(f'{irs_raw_folder_path}/{i}', encoding='latin-1') #irs formatting requires this encoding\n",
    "    file = file.drop(['STATEFIPS','AGI_STUB','COUNTYFIPS'],axis=1).reset_index(drop=True) # drop columns not used for the current analysis, but raw files are presevered for future use.\n",
    "        \n",
    "    # Lambda function to generate a boolian mask filtering 'COUNTYNAME' values with a single word, \n",
    "    # removing all single name counties (should be agg. state data)\n",
    "    filter_counties = lambda row: len(row['COUNTYNAME'].split()) >=2\n",
    "    data_counties = file[file.apply(filter_counties, axis=1)]\n",
    "    lower_countynames = [i.lower() for i in data_counties['COUNTYNAME']]\n",
    "    data_copy = data_counties.copy()\n",
    "    data_copy['COUNTYNAME'] = lower_countynames\n",
    "    \n",
    "    # Generate a name for each dataframe based on the filename without the file extension\n",
    "    name = f'{i[:-4]}+_f' \n",
    "    name = name[:-4]+'_f' \n",
    "    \n",
    "    # Assign the dataframe to the variable name\n",
    "    # globals()[name] = data_copy # from the documentation: 'the globals() function is a built-in function that returns a dictionary representing the current global symbol table' only half understand this, but it works (#programming)\n",
    "    \n",
    "    # Append both to the empty list\n",
    "    processed_irs_files.append((name, data_copy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b7748952-06c7-443c-ab4a-709c7631a2f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting list of common columns\n",
      "Processing IRS data, Writing IRS data to /irs_data\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "\"['STATE_df1', 'COUNTYNAME_df1', 'STATE_df2', 'COUNTYNAME_df2'] not found in axis\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[14], line 49\u001b[0m\n\u001b[0;32m     46\u001b[0m arg2 \u001b[38;5;241m=\u001b[39m arg2[common_col]\n\u001b[0;32m     48\u001b[0m \u001b[38;5;66;03m# Run the function to subtract one year's data from the previous year's data\u001b[39;00m\n\u001b[1;32m---> 49\u001b[0m df_diff \u001b[38;5;241m=\u001b[39m prev_year_change2(arg1, arg2)\n\u001b[0;32m     51\u001b[0m \u001b[38;5;66;03m# Name of new variable\u001b[39;00m\n\u001b[0;32m     52\u001b[0m new_df \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mprocessed_irs_files[i][\u001b[38;5;241m0\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_d2\u001b[39m\u001b[38;5;124m'\u001b[39m\n",
      "Cell \u001b[1;32mIn[14], line 18\u001b[0m, in \u001b[0;36mprev_year_change2\u001b[1;34m(data1, data2)\u001b[0m\n\u001b[0;32m     15\u001b[0m         merged_df[column] \u001b[38;5;241m=\u001b[39m merged_df[column \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_df1\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m-\u001b[39m merged_df[column \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_df2\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m     17\u001b[0m \u001b[38;5;66;03m# Drop redundant columns\u001b[39;00m\n\u001b[1;32m---> 18\u001b[0m merged_df\u001b[38;5;241m.\u001b[39mdrop(columns\u001b[38;5;241m=\u001b[39m[col \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_df1\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m col \u001b[38;5;129;01min\u001b[39;00m data1\u001b[38;5;241m.\u001b[39mcolumns] \u001b[38;5;241m+\u001b[39m [col \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_df2\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m col \u001b[38;5;129;01min\u001b[39;00m data2\u001b[38;5;241m.\u001b[39mcolumns], inplace\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m merged_df\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\frame.py:5258\u001b[0m, in \u001b[0;36mDataFrame.drop\u001b[1;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[0;32m   5110\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdrop\u001b[39m(\n\u001b[0;32m   5111\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   5112\u001b[0m     labels: IndexLabel \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   5119\u001b[0m     errors: IgnoreRaise \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraise\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   5120\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   5121\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   5122\u001b[0m \u001b[38;5;124;03m    Drop specified labels from rows or columns.\u001b[39;00m\n\u001b[0;32m   5123\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   5256\u001b[0m \u001b[38;5;124;03m            weight  1.0     0.8\u001b[39;00m\n\u001b[0;32m   5257\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 5258\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mdrop(\n\u001b[0;32m   5259\u001b[0m         labels\u001b[38;5;241m=\u001b[39mlabels,\n\u001b[0;32m   5260\u001b[0m         axis\u001b[38;5;241m=\u001b[39maxis,\n\u001b[0;32m   5261\u001b[0m         index\u001b[38;5;241m=\u001b[39mindex,\n\u001b[0;32m   5262\u001b[0m         columns\u001b[38;5;241m=\u001b[39mcolumns,\n\u001b[0;32m   5263\u001b[0m         level\u001b[38;5;241m=\u001b[39mlevel,\n\u001b[0;32m   5264\u001b[0m         inplace\u001b[38;5;241m=\u001b[39minplace,\n\u001b[0;32m   5265\u001b[0m         errors\u001b[38;5;241m=\u001b[39merrors,\n\u001b[0;32m   5266\u001b[0m     )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\generic.py:4549\u001b[0m, in \u001b[0;36mNDFrame.drop\u001b[1;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[0;32m   4547\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m axis, labels \u001b[38;5;129;01min\u001b[39;00m axes\u001b[38;5;241m.\u001b[39mitems():\n\u001b[0;32m   4548\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m labels \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 4549\u001b[0m         obj \u001b[38;5;241m=\u001b[39m obj\u001b[38;5;241m.\u001b[39m_drop_axis(labels, axis, level\u001b[38;5;241m=\u001b[39mlevel, errors\u001b[38;5;241m=\u001b[39merrors)\n\u001b[0;32m   4551\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m inplace:\n\u001b[0;32m   4552\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_inplace(obj)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\generic.py:4591\u001b[0m, in \u001b[0;36mNDFrame._drop_axis\u001b[1;34m(self, labels, axis, level, errors, only_slice)\u001b[0m\n\u001b[0;32m   4589\u001b[0m         new_axis \u001b[38;5;241m=\u001b[39m axis\u001b[38;5;241m.\u001b[39mdrop(labels, level\u001b[38;5;241m=\u001b[39mlevel, errors\u001b[38;5;241m=\u001b[39merrors)\n\u001b[0;32m   4590\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 4591\u001b[0m         new_axis \u001b[38;5;241m=\u001b[39m axis\u001b[38;5;241m.\u001b[39mdrop(labels, errors\u001b[38;5;241m=\u001b[39merrors)\n\u001b[0;32m   4592\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m axis\u001b[38;5;241m.\u001b[39mget_indexer(new_axis)\n\u001b[0;32m   4594\u001b[0m \u001b[38;5;66;03m# Case for non-unique axis\u001b[39;00m\n\u001b[0;32m   4595\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:6699\u001b[0m, in \u001b[0;36mIndex.drop\u001b[1;34m(self, labels, errors)\u001b[0m\n\u001b[0;32m   6697\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mask\u001b[38;5;241m.\u001b[39many():\n\u001b[0;32m   6698\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m errors \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m-> 6699\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlist\u001b[39m(labels[mask])\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not found in axis\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   6700\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m indexer[\u001b[38;5;241m~\u001b[39mmask]\n\u001b[0;32m   6701\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdelete(indexer)\n",
      "\u001b[1;31mKeyError\u001b[0m: \"['STATE_df1', 'COUNTYNAME_df1', 'STATE_df2', 'COUNTYNAME_df2'] not found in axis\""
     ]
    }
   ],
   "source": [
    "def prev_year_change2(data1, data2):\n",
    "    \"\"\"\n",
    "    This function will substitute the difference between a year and the previous year's IRS records, \n",
    "    Giving us the change-over-year and letting us use that as an indication of economic growth/loss\n",
    "    \n",
    "    NOTE: data1 should be the election year, data2 should be the previous year.\n",
    "    \"\"\"\n",
    "\n",
    "    # Merge based on 'STATE' and 'COUNTYNAME' columns\n",
    "    merged_df = pd.merge(data1, data2, on=['STATE', 'COUNTYNAME'], suffixes=('_df1', '_df2'))\n",
    "\n",
    "    # Subtract values in df2 from df1 for columns where the names match\n",
    "    for column in data1.columns:\n",
    "        if column not in ['STATE', 'COUNTYNAME']:\n",
    "            merged_df[column] = merged_df[column + '_df1'] - merged_df[column + '_df2']\n",
    "\n",
    "    # Drop redundant columns\n",
    "    merged_df.drop(columns=[col + '_df1' for col in data1.columns] + [col + '_df2' for col in data2.columns], inplace=True)\n",
    "\n",
    "    return merged_df\n",
    "\n",
    "print(\"Getting list of common columns\")\n",
    "\n",
    "common_col = set(processed_irs_files[0][1].columns)\n",
    "\n",
    "# Iterate over even-year items (election years)\n",
    "for i in processed_irs_files[1:]:\n",
    "    current_col = set(i[1].columns)\n",
    "    common_col = common_col & current_col\n",
    "\n",
    "common_col = list(common_col)\n",
    "\n",
    "print(\"Processing IRS data, Writing IRS data to /irs_data\")\n",
    "\n",
    "# Iterate through processed_irs_files\n",
    "for i in range(0, len(processed_irs_files), 2):  # Increment by 2 to get even-year items\n",
    "\n",
    "    # Extract DataFrames and filenames\n",
    "    arg1 = processed_irs_files[i][1]\n",
    "    arg2 = processed_irs_files[i + 1][1] if i + 1 < len(processed_irs_files) else None\n",
    "    name = processed_irs_files[i][0]\n",
    "\n",
    "    # Drop columns not in common_col\n",
    "    arg1 = arg1[common_col]\n",
    "    if arg2 is not None:\n",
    "        arg2 = arg2[common_col]\n",
    "\n",
    "        # Run the function to subtract one year's data from the previous year's data\n",
    "        df_diff = prev_year_change2(arg1, arg2)\n",
    "\n",
    "        # Name of new variable\n",
    "        new_df = f'{processed_irs_files[i][0]}_d2'\n",
    "\n",
    "        # Create the directory if it doesn't exist\n",
    "        os.makedirs(irs_folder_path, exist_ok=True)\n",
    "\n",
    "        # Save the DataFrames as CSV files\n",
    "        csv_filename_f = f'{name}.csv'\n",
    "        csv_filename_d = f'{new_df}.csv'\n",
    "        arg1.to_csv(os.path.join(irs_folder_path, csv_filename_f), index=False)  # the 'original' formatted files for each election year\n",
    "        df_diff.to_csv(os.path.join(irs_folder_path, csv_filename_d), index=False)  # the file processed by the prev_year_change function\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "333ac070-1c75-4493-8350-aa5611ac45e4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "processed_irs_files[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6db9f40-1425-47aa-ab50-e690770d2251",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "common_col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3052486f-f09e-4b60-8b99-86b7de727853",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "len(common_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "181592ed-96e9-4d27-a0ab-5ec4cd438f18",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prev_year_change2(data1, data2):\n",
    "    \"\"\"\n",
    "    This function will substitute the difference between a year and the previous year's IRS records, \n",
    "    Giving us the change-over-year and letting us use that as an indication of economic growth/loss\n",
    "    \n",
    "    NOTE: data1 should be the election  year, data2 should be the previous year.\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "    merged_df = pd.merge(data1, data2, on=['STATE', 'COUNTYNAME'], suffixes=('_df1', '_df2'))\n",
    "\n",
    "    # Subtract values in df1 from df2 for columns where the names match\n",
    "    for column in data1.columns:\n",
    "        if column not in ['STATE', 'COUNTYNAME']:\n",
    "            merged_df[column] = merged_df[column + '_df1'] - merged_df[column + '_df2']\n",
    "\n",
    "    # Drop redundant columns\n",
    "    merged_df.drop(columns=[col + '_df1' for col in data1.columns] + [col + '_df2' for col in data2.columns], inplace=True)\n",
    "\n",
    "    return merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b7a502c-ffdd-4d1d-b408-c12ccb1e893b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(\"Getting list of common columns\")\n",
    "\n",
    "common_col = set(processed_irs_files[0][1].columns)\n",
    "\n",
    "# Iterate over even-year items (election years)\n",
    "for i in processed_irs_files[1:]:\n",
    "    \n",
    "    current_col = set(i[1].columns)\n",
    "    common_col = common_col & current_col\n",
    "    \n",
    "common_col = list(common_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b424af87-5a9a-47c8-8c5d-f273494eb373",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming common_col is a list containing common column names\n",
    "\n",
    "print(\"Processing IRS data, Writing IRS data to /irs_data\")\n",
    "\n",
    "# Iterate through processed_irs_files\n",
    "for i in range(0, len(processed_irs_files), 2):  # Increment by 2 to get even-year items\n",
    "\n",
    "    # Extract DataFrames and filenames\n",
    "    arg1 = processed_irs_files[i][1]\n",
    "    arg2 = processed_irs_files[i + 1][1] if i + 1 < len(processed_irs_files) else None\n",
    "    name = processed_irs_files[i][0]\n",
    "\n",
    "    # Drop columns not in common_col\n",
    "    arg1 = arg1[common_col]\n",
    "    if arg2 is not None:\n",
    "        arg2 = arg2[common_col]\n",
    "\n",
    "        # Run the function to subtract one year's data from the previous year's data\n",
    "        df_diff = prev_year_change2(arg1, arg2)\n",
    "\n",
    "        # Name of new variable\n",
    "        new_df = f'{processed_irs_files[i][0]}_d2'\n",
    "\n",
    "        # Create the directory if it doesn't exist\n",
    "        os.makedirs(irs_folder_path, exist_ok=True)\n",
    "\n",
    "        # Save the DataFrames as CSV files\n",
    "        csv_filename_f = f'{name}.csv'\n",
    "        csv_filename_d = f'{new_df}.csv'\n",
    "        arg1.to_csv(os.path.join(irs_folder_path, csv_filename_f), index=False)  # the 'original' formatted files for each election year\n",
    "        df_diff.to_csv(os.path.join(irs_folder_path, csv_filename_d), index=False)  # the file processed by the prev_year_change function\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5edbbd77-79b5-409e-9c77-9f8630bb1de0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "processed_irs_files[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdb52a79-18de-4d33-8bdf-84236b598901",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
