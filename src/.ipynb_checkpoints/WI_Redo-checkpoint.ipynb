{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "47a9eb2c-8433-4e84-a64f-c72616e835b9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from modules import *\n",
    "\n",
    "import os #Used when reading/writing csv files programatically"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dc0700a4-07c1-417c-8c85-b214663d0b92",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fed_folder_path = '../data/FEC/'\n",
    "\n",
    "fec_files = [file for file in os.listdir(fed_folder_path) if os.path.isfile(os.path.join(fed_folder_path, file))]\n",
    "\n",
    "# Empty list to hold FEC files\n",
    "FEC_files = []\n",
    "\n",
    "for i in fec_files: # Call item in the file list\n",
    "    \n",
    "    # Read each file from the FEC file list\n",
    "    file = pd.read_csv(fr'{fed_folder_path}{i}', index_col=0)\n",
    "    \n",
    "    \n",
    "    # Generate a name for each dataframe based on the filename without the file extension\n",
    "    name = f'{i}' \n",
    "    name = name[:-4] \n",
    "    \n",
    "    # Assign the dataframe to the variable name\n",
    "    globals()[name] = file # from the documentation: 'the globals() function is a built-in function that returns a dictionary representing the current global symbol table' only half understand this, but it works (#programming)\n",
    "    \n",
    "    # Append both to the empty list\n",
    "    FEC_files.append(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fac5a90c-95c9-49ba-b74b-027734f7ab64",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# All raw election data is stored in the same folder, ordered by the State abbreviation.\n",
    "\n",
    "elec_folder_path = 'data/raw_elec_totals'\n",
    "\n",
    "WI_files = [file for file in os.listdir(elec_folder_path) if os.path.isfile(os.path.join(elec_folder_path, file)) and file.startswith('WI')]\n",
    "\n",
    "# Get a list of sheetnames in the WI data files\n",
    "WI_sheetnames = []\n",
    "for i in WI_files:\n",
    "    file = pd.ExcelFile(f'{elec_folder_path}/{i}')\n",
    "    WI_sheetnames = [i for i in file.sheet_names if i.startswith('Sheet')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7c057653-de04-4635-8f7d-9fe79783d156",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "WI_cong = []\n",
    "\n",
    "for i in WI_files:\n",
    "    # Create name based on filename\n",
    "    name = i[:7]\n",
    "    \n",
    "    # Read file to get sheet names\n",
    "    file = pd.ExcelFile(f'{elec_folder_path}/{i}')\n",
    "    WI_sheetnames = [i for i in file.sheet_names if i.startswith('Sheet')]\n",
    "    \n",
    "    # expected column names to reformat\n",
    "    col_dic = {'Unnamed: 0':'County'} \n",
    "    drop_col = ['Unnamed: 1', 'Unnamed: 2','SCATTERING']\n",
    "    \n",
    "    # Empty dataframe to hold sheets as they are concatinated\n",
    "    data = pd.DataFrame()\n",
    "    \n",
    "    for sheet in WI_sheetnames:\n",
    "        current_sheet = pd.read_excel(f'{elec_folder_path}/{i}', sheet_name=sheet, header=5)\n",
    "        data = pd.concat([data, current_sheet], ignore_index=True)\n",
    "    \n",
    "    # All sheets should be read in and concatinated\n",
    "    \n",
    "    # Drop the columns containing vote totals per county and the empty 2rd column\n",
    "    data_copy = data.drop(columns=drop_col)\n",
    "    # Rename 'County' column to 'County'\n",
    "    data_copy = data_copy.rename(columns=col_dic) \n",
    "    data_copy = data_copy[~data_copy['County'].str.contains('Total')].copy()\n",
    "    data_copy = data_copy.groupby('County').sum().reset_index()\n",
    "    data_copy['County'] = [i.lower().strip() for i in data_copy['County'].tolist()]\n",
    "    \n",
    "    # To begin, candidate names will be rendered in all lowers to match the FEC data\n",
    "    cols = data_copy.columns.tolist()\n",
    "    cols = [i.lower() for i in cols]\n",
    "    \n",
    "    # Drop party/write-in lables and remove middle names\n",
    "    cols = trim_party(cols)\n",
    "    cols = remove_middle_name(cols)\n",
    "    cols = [''.join(char for char in i if char.isalpha() or char.isspace()) for i in cols]\n",
    "    data_copy.columns = cols\n",
    "    data_copy = data_copy.fillna(0)\n",
    "    \n",
    "    WI_cong.append((name,data_copy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "af59bc3d-16ba-4923-884e-bc5c25c9b1d9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create zipped list of formatted State Election data, FEC list of candidates and parties, and the filenames found in raw_elec data\n",
    "zipped_WI_FEC = zip(formatted_WI, FEC_files, WI_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "45c01f2a-64e6-4f42-aadd-93d25e01f411",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Further process and transform election data, grouping vote totals by party and incumbancy\n",
    "# Allows analysis on these two metrics\n",
    "for i, j, k in zipped_WI_FEC:\n",
    "    \n",
    "    # Joins FEC and State data for each year, produces list of counties as well\n",
    "    # If an error is generated here, there is likely a mismatch between the counties in these files\n",
    "    formatted_WI_FEC, counties = state_join_FEC(i,j)\n",
    "    transformed_data = state_trans(formatted_WI_FEC, counties)\n",
    "    \n",
    "    # Writes the transformed data to a .csv file whose name references the original filename\n",
    "    transformed_data.to_csv(fr\"../data/formatted_house_totals/{k[:7]}.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d66126b1-2569-42f1-8062-b37107596688",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>county</th>\n",
       "      <th>paul ryan</th>\n",
       "      <th>rob zerban</th>\n",
       "      <th>keith deschler</th>\n",
       "      <th>chad lee</th>\n",
       "      <th>mark pocan</th>\n",
       "      <th>joe kopsick</th>\n",
       "      <th>ray boland</th>\n",
       "      <th>ron kind</th>\n",
       "      <th>dan sebring</th>\n",
       "      <th>...</th>\n",
       "      <th>robert raymond</th>\n",
       "      <th>f. sensenbrenner</th>\n",
       "      <th>dave heaster</th>\n",
       "      <th>tom petri</th>\n",
       "      <th>joe kallas</th>\n",
       "      <th>sean duffy</th>\n",
       "      <th>pat kreitlow</th>\n",
       "      <th>dale lehner</th>\n",
       "      <th>reid ribble</th>\n",
       "      <th>jamie wall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>adams</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3799.0</td>\n",
       "      <td>5183.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ashland</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3172.0</td>\n",
       "      <td>5051.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>barron</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11621.0</td>\n",
       "      <td>9708.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>bayfield</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4026.0</td>\n",
       "      <td>5573.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>brown</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>67021.0</td>\n",
       "      <td>55730.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>waukesha</td>\n",
       "      <td>37026.0</td>\n",
       "      <td>13164.0</td>\n",
       "      <td>724.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>113469.0</td>\n",
       "      <td>44074.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>waupaca</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14342.0</td>\n",
       "      <td>9919.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>waushara</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7160.0</td>\n",
       "      <td>4009.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>winnebago</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>45824.0</td>\n",
       "      <td>32411.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4141.0</td>\n",
       "      <td>2318.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>wood</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9104.0</td>\n",
       "      <td>12238.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9432.0</td>\n",
       "      <td>6059.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>72 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        county  paul ryan  rob zerban  keith deschler  chad lee  mark pocan  \\\n",
       "0       adams         0.0         0.0             0.0       0.0         0.0   \n",
       "1     ashland         0.0         0.0             0.0       0.0         0.0   \n",
       "2      barron         0.0         0.0             0.0       0.0         0.0   \n",
       "3    bayfield         0.0         0.0             0.0       0.0         0.0   \n",
       "4       brown         0.0         0.0             0.0       0.0         0.0   \n",
       "..         ...        ...         ...             ...       ...         ...   \n",
       "68   waukesha     37026.0     13164.0           724.0       0.0         0.0   \n",
       "69    waupaca         0.0         0.0             0.0       0.0         0.0   \n",
       "70   waushara         0.0         0.0             0.0       0.0         0.0   \n",
       "71  winnebago         0.0         0.0             0.0       0.0         0.0   \n",
       "72       wood         0.0         0.0             0.0       0.0         0.0   \n",
       "\n",
       "    joe kopsick  ray boland  ron kind  dan sebring  ...  robert raymond  \\\n",
       "0           0.0      3799.0    5183.0          0.0  ...             0.0   \n",
       "1           0.0         0.0       0.0          0.0  ...             0.0   \n",
       "2           0.0         0.0       0.0          0.0  ...             0.0   \n",
       "3           0.0         0.0       0.0          0.0  ...             0.0   \n",
       "4           0.0         0.0       0.0          0.0  ...             0.0   \n",
       "..          ...         ...       ...          ...  ...             ...   \n",
       "68          0.0         0.0       0.0          0.0  ...             0.0   \n",
       "69          0.0         0.0       0.0          0.0  ...             0.0   \n",
       "70          0.0         0.0       0.0          0.0  ...             0.0   \n",
       "71          0.0         0.0       0.0          0.0  ...             0.0   \n",
       "72          0.0      9104.0   12238.0          0.0  ...             0.0   \n",
       "\n",
       "    f. sensenbrenner  dave heaster  tom petri  joe kallas  sean duffy  \\\n",
       "0                0.0           0.0        0.0         0.0         0.0   \n",
       "1                0.0           0.0        0.0         0.0      3172.0   \n",
       "2                0.0           0.0        0.0         0.0     11621.0   \n",
       "3                0.0           0.0        0.0         0.0      4026.0   \n",
       "4                0.0           0.0        0.0         0.0         0.0   \n",
       "..               ...           ...        ...         ...         ...   \n",
       "68          113469.0       44074.0        0.0         0.0         0.0   \n",
       "69               0.0           0.0        0.0         0.0         0.0   \n",
       "70               0.0           0.0     7160.0      4009.0         0.0   \n",
       "71               0.0           0.0    45824.0     32411.0         0.0   \n",
       "72               0.0           0.0        0.0         0.0      9432.0   \n",
       "\n",
       "    pat kreitlow  dale lehner  reid ribble  jamie wall  \n",
       "0            0.0          0.0          0.0         0.0  \n",
       "1         5051.0          0.0          0.0         0.0  \n",
       "2         9708.0         17.0          0.0         0.0  \n",
       "3         5573.0          0.0          0.0         0.0  \n",
       "4            0.0          0.0      67021.0     55730.0  \n",
       "..           ...          ...          ...         ...  \n",
       "68           0.0          0.0          0.0         0.0  \n",
       "69           0.0          0.0      14342.0      9919.0  \n",
       "70           0.0          0.0          0.0         0.0  \n",
       "71           0.0          0.0       4141.0      2318.0  \n",
       "72        6059.0          1.0          0.0         0.0  \n",
       "\n",
       "[72 rows x 21 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "formatted_WI[0][]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6ab7acc7-a24f-4f07-b828-eb7266cb0e25",
   "metadata": {},
   "outputs": [],
   "source": [
    "irs_folder_path = '../data/irs_data/'\n",
    "\n",
    "irs_files = [file for file in os.listdir(irs_folder_path) if os.path.isfile(os.path.join(irs_folder_path, file))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0eea6024-04da-4341-a17c-2bb7de434a96",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "house_data_path = '../data/formatted_house_totals/'\n",
    "\n",
    "WI_formatted = [file for file in os.listdir(house_data_path) if os.path.isfile(os.path.join(house_data_path, file)) and file.startswith('WI')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e49ae320-b4cf-402c-937c-e09ff29d6cf5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counties mismatch in WI_2012.csv: ['adams', 'ashland', 'barron', 'bayfield', 'brown', 'buffalo', 'burnett', 'calumet', 'chippewa', 'clark', 'columbia', 'crawford', 'dane', 'dodge', 'door', 'douglas', 'dunn', 'eau claire', 'florence', 'fond du lac', 'forest', 'grant', 'green', 'green lake', 'iowa', 'iron', 'jackson', 'jefferson', 'juneau', 'kenosha', 'kewaunee', 'la crosse', 'lafayette', 'langlade', 'lincoln', 'manitowoc', 'marathon', 'marinette', 'marquette', 'menominee', 'milwaukee', 'monroe', 'oconto', 'oneida', 'outagamie', 'ozaukee', 'pepin', 'pierce', 'polk', 'portage', 'price', 'racine', 'richland', 'rock', 'rusk', 'st. croix', 'sauk', 'sawyer', 'shawano', 'sheboygan', 'taylor', 'trempealeau', 'vernon', 'vilas', 'walworth', 'washburn', 'washington', 'waukesha', 'waupaca', 'waushara', 'winnebago', 'wood']\n",
      "Counties mismatch in WI_2014.csv: ['adams', 'ashland', 'barron', 'bayfield', 'brown', 'buffalo', 'burnett', 'calumet', 'chippewa', 'clark', 'columbia', 'crawford', 'dane', 'dodge', 'door', 'douglas', 'dunn', 'eau claire', 'florence', 'fond du lac', 'forest', 'grant', 'green', 'green lake', 'iowa', 'iron', 'jackson', 'jefferson', 'juneau', 'kenosha', 'kewaunee', 'la crosse', 'lafayette', 'langlade', 'lincoln', 'manitowoc', 'marathon', 'marinette', 'marquette', 'menominee', 'milwaukee', 'monroe', 'oconto', 'oneida', 'outagamie', 'ozaukee', 'pepin', 'pierce', 'polk', 'portage', 'price', 'racine', 'richland', 'rock', 'rusk', 'st. croix', 'sauk', 'sawyer', 'shawano', 'sheboygan', 'taylor', 'trempealeau', 'vernon', 'vilas', 'walworth', 'washburn', 'washington', 'waukesha', 'waupaca', 'waushara', 'winnebago', 'wood']\n",
      "Counties mismatch in WI_2016.csv: ['adams', 'ashland', 'barron', 'bayfield', 'brown', 'buffalo', 'burnett', 'calumet', 'chippewa', 'clark', 'columbia', 'crawford', 'dane', 'dodge', 'door', 'douglas', 'dunn', 'eau claire', 'florence', 'fond du lac', 'forest', 'grant', 'green', 'green lake', 'iowa', 'iron', 'jackson', 'jefferson', 'juneau', 'kenosha', 'kewaunee', 'la crosse', 'lafayette', 'langlade', 'lincoln', 'manitowoc', 'marathon', 'marinette', 'marquette', 'menominee', 'milwaukee', 'monroe', 'oconto', 'oneida', 'outagamie', 'ozaukee', 'pepin', 'pierce', 'polk', 'portage', 'price', 'racine', 'richland', 'rock', 'rusk', 'st. croix', 'sauk', 'sawyer', 'shawano', 'sheboygan', 'taylor', 'trempealeau', 'vernon', 'vilas', 'walworth', 'washburn', 'washington', 'waukesha', 'waupaca', 'waushara', 'winnebago', 'wood']\n",
      "Counties mismatch in WI_2018.csv: ['adams', 'ashland', 'barron', 'bayfield', 'brown', 'buffalo', 'burnett', 'calumet', 'chippewa', 'clark', 'columbia', 'crawford', 'dane', 'dodge', 'door', 'douglas', 'dunn', 'eau claire', 'florence', 'fond du lac', 'forest', 'grant', 'green', 'green lake', 'iowa', 'iron', 'jackson', 'jefferson', 'juneau', 'kenosha', 'kewaunee', 'la crosse', 'lafayette', 'langlade', 'lincoln', 'manitowoc', 'marathon', 'marinette', 'marquette', 'menominee', 'milwaukee', 'monroe', 'oconto', 'oneida', 'outagamie', 'ozaukee', 'pepin', 'pierce', 'polk', 'portage', 'price', 'racine', 'richland', 'rock', 'rusk', 'st. croix', 'sauk', 'sawyer', 'shawano', 'sheboygan', 'taylor', 'trempealeau', 'vernon', 'vilas', 'walworth', 'washburn', 'washington', 'waukesha', 'waupaca', 'waushara', 'winnebago', 'wood']\n",
      "Counties mismatch in WI_2020.csv: ['adams', 'ashland', 'barron', 'bayfield', 'brown', 'buffalo', 'burnett', 'calumet', 'chippewa', 'clark', 'columbia', 'crawford', 'dane', 'dodge', 'door', 'douglas', 'dunn', 'eau claire', 'florence', 'fond du lac', 'forest', 'grant', 'green', 'green lake', 'iowa', 'iron', 'jackson', 'jefferson', 'juneau', 'kenosha', 'kewaunee', 'la crosse', 'lafayette', 'langlade', 'lincoln', 'manitowoc', 'marathon', 'marinette', 'marquette', 'menominee', 'milwaukee', 'monroe', 'oconto', 'oneida', 'outagamie', 'ozaukee', 'pepin', 'pierce', 'polk', 'portage', 'price', 'racine', 'richland', 'rock', 'rusk', 'st. croix', 'sauk', 'sawyer', 'shawano', 'sheboygan', 'taylor', 'trempealeau', 'vernon', 'vilas', 'walworth', 'washburn', 'washington', 'waukesha', 'waupaca', 'waushara', 'winnebago', 'wood']\n"
     ]
    }
   ],
   "source": [
    "county_check = []\n",
    "for i in WI_formatted:\n",
    "    state = i[0:2] #first two letters of the filename, corresponding to the state abbv.\n",
    "    year = i[5:7] #two digit year \n",
    "    \n",
    "    # Import house file\n",
    "    house = pd.read_csv(f'{house_data_path}{i}')\n",
    "    \n",
    "    irs = pd.read_csv(f'{irs_folder_path}irs_count_20{year}_f.csv')\n",
    "    \n",
    "    # Get IRS data only for the relevant state (this is done to ensure that states with identicle county names do not have their data mixed)\n",
    "    irs_state = irs.loc[irs['STATE']==state]\n",
    "    irs_county = irs_state['COUNTYNAME'].tolist()\n",
    "    # irs_county = [i for i in remove_keyword(irs_county,'county')] # format to match the House data\n",
    "    \n",
    "    # Due to the length of some county names and the character limit of the 'COUNTYNAME' field in the original IRS data\n",
    "    # some counties have 'County' displayed as 'Count', 'Coun' or 'Co'\n",
    "    # Thus, the current solution will instead by to drop the final word\n",
    "    irs_county = [' '.join(i.split()[:-1]) for i in irs_county]\n",
    "    \n",
    "    #These two counties are misnamed in the IRS data\n",
    "    irs_misnamed = {'de witt':'dewitt','jo daviess':'jodaviess'}\n",
    "    # This '.get's (haha) the correct county names\n",
    "    cor_counties = [irs_misnamed.get(item, item) for item in irs_county]\n",
    "    \n",
    "    irs_copy = irs_state.copy() #avoid setting a value on a copy of a slice\n",
    "    irs_copy['COUNTYNAME'] = cor_counties\n",
    "    \n",
    "    # Check if any county names do not match between the state data and the IRS data, if so, add to the 'county_check' list\n",
    "    unmatched_counties = [county for county in irs_copy['COUNTYNAME'].tolist() if county not in house['County'].tolist()]\n",
    "    if len(unmatched_counties) > 0:\n",
    "        print(f\"Counties mismatch in {i}: {unmatched_counties}\")\n",
    "        county_check.append('1')\n",
    "    else:\n",
    "        print(f\"IRS data merged with {i}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9c342c1-12f7-45d9-905f-e2c317983c35",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
