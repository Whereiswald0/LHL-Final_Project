{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "afd19682-5876-42d6-9670-f6ae17d21276",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute 'append'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_13568\\1352612173.py\u001b[0m in \u001b[0;36m?\u001b[1;34m()\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m     \u001b[1;31m# Check if there are any values greater than zero\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mfiltered_values\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mempty\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m         \u001b[1;31m# Append values and corresponding column names to the result dataframe\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 23\u001b[1;33m         result_dataframe = result_dataframe.append({'Value': filtered_values.values,\n\u001b[0m\u001b[0;32m     24\u001b[0m                                                     'Column': [column] * len(filtered_values)},\n\u001b[0;32m     25\u001b[0m                                                    ignore_index=True)\n\u001b[0;32m     26\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   5985\u001b[0m             \u001b[1;32mand\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_accessors\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5986\u001b[0m             \u001b[1;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_can_hold_identifiers_and_holds_name\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5987\u001b[0m         ):\n\u001b[0;32m   5988\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 5989\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'append'"
     ]
    }
   ],
   "source": [
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Assuming you have an existing dataframe named 'original_dataframe'\n",
    "# Replace this with your actual dataframe or create one for testing\n",
    "\n",
    "# Example DataFrame\n",
    "data = {'A': [1, -2, 3, 0],\n",
    "        'B': [-4, 5, 0, 7],\n",
    "        'C': [0, 0, 0, 0]}\n",
    "original_dataframe = pd.DataFrame(data)\n",
    "\n",
    "# Create a new dataframe to store the results\n",
    "result_dataframe = pd.DataFrame(columns=['Value', 'Column'])\n",
    "\n",
    "# Iterate over columns in the original dataframe\n",
    "for column in original_dataframe.columns:\n",
    "    # Filter values greater than zero\n",
    "    filtered_values = original_dataframe[column][original_dataframe[column] > 0]\n",
    "    \n",
    "    # Check if there are any values greater than zero\n",
    "    if not filtered_values.empty:\n",
    "        # Append values and corresponding column names to the result dataframe\n",
    "        result_dataframe = result_dataframe.append({'Value': filtered_values.values,\n",
    "                                                    'Column': [column] * len(filtered_values)},\n",
    "                                                   ignore_index=True)\n",
    "\n",
    "# Display the result dataframe\n",
    "print(result_dataframe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e5fa75f1-9543-4a3d-8574-9df94c1db0af",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Value Column\n",
      "0      1      A\n",
      "1      3      A\n",
      "2      5      B\n",
      "3      7      B\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Assuming you have an existing dataframe named 'original_dataframe'\n",
    "# Replace this with your actual dataframe or create one for testing\n",
    "\n",
    "# Example DataFrame\n",
    "data = {'A': [1, -2, 3, 0],\n",
    "        'B': [-4, 5, 0, 7],\n",
    "        'C': [0, 0, 0, 0]}\n",
    "original_dataframe = pd.DataFrame(data)\n",
    "\n",
    "# Create empty lists to store values and corresponding column names\n",
    "values_list = []\n",
    "columns_list = []\n",
    "\n",
    "# Iterate over columns in the original dataframe\n",
    "for column in original_dataframe.columns:\n",
    "    # Filter values greater than zero\n",
    "    filtered_values = original_dataframe[column][original_dataframe[column] > 0]\n",
    "    \n",
    "    # Check if there are any values greater than zero\n",
    "    if not filtered_values.empty:\n",
    "        # Append values and corresponding column names to the lists\n",
    "        values_list.extend(filtered_values.tolist())\n",
    "        columns_list.extend([column] * len(filtered_values))\n",
    "\n",
    "# Create a new dataframe from the lists\n",
    "result_dataframe = pd.DataFrame({'Value': values_list, 'Column': columns_list})\n",
    "\n",
    "# Display the result dataframe\n",
    "print(result_dataframe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "60da4a68-bbf0-4e2d-b6aa-c2c2e1e712ff",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   New Beth  John Doe_A\n",
      "0         1           4\n",
      "1         2           5\n",
      "2         3           6\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Assuming you have two dataframes named 'df_A' and 'df_B'\n",
    "# Replace these with your actual dataframes or create them for testing\n",
    "\n",
    "# Example DataFrames\n",
    "data_A = {'Beth Jean': [1, 2, 3], 'John Doe_A': [4, 5, 6]}\n",
    "df_A = pd.DataFrame(data_A)\n",
    "\n",
    "data_B = {'Old_Name': ['Beth Jean', 'John Doe'], 'New_Name': ['New Beth', 'New John']}\n",
    "df_B = pd.DataFrame(data_B)\n",
    "\n",
    "# Create a dictionary mapping old names to new names\n",
    "column_mapping = dict(zip(df_B['Old_Name'], df_B['New_Name']))\n",
    "\n",
    "# Rename columns in DataFrame A using the dictionary\n",
    "df_A.columns = df_A.columns.map(lambda x: column_mapping[x] if x in column_mapping else x)\n",
    "\n",
    "# Display the modified DataFrame A\n",
    "print(df_A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d5b45001-9c88-4fab-842f-504a23cd43b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ID  Value  Other\n",
      "0   1     15    150\n",
      "1   2     30    300\n",
      "2   3     45    450\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Assuming you have two dataframes df1 and df2\n",
    "# Let's create some example dataframes for illustration purposes\n",
    "data1 = {'ID': [1, 2, 3], 'Value': [10, 20, 30], 'Other': [100, 200, 300]}\n",
    "data2 = {'ID': [1, 2, 3], 'Value': [5, 10, 15], 'Other': [50, 100, 150]}\n",
    "df1 = pd.DataFrame(data1)\n",
    "df2 = pd.DataFrame(data2)\n",
    "\n",
    "# Set the 'ID' column as the index for both dataframes\n",
    "df1.set_index('ID', inplace=True)\n",
    "df2.set_index('ID', inplace=True)\n",
    "\n",
    "# Add the values of the two dataframes\n",
    "result_df = df1.add(df2, fill_value=0)\n",
    "\n",
    "# Reset the index to make 'ID' a regular column again\n",
    "result_df.reset_index(inplace=True)\n",
    "\n",
    "# Print the resulting dataframe\n",
    "print(result_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9a4eb275-4b90-47da-9576-966dbf2145cc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "You are trying to merge on int64 and object columns. If you wish to proceed you should use pd.concat",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 21\u001b[0m\n\u001b[0;32m     18\u001b[0m candidates_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(candidates_data)\n\u001b[0;32m     20\u001b[0m \u001b[38;5;66;03m# Step 1: Merge dataframes to map candidate name to party\u001b[39;00m\n\u001b[1;32m---> 21\u001b[0m merged_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mmerge(votes_df, candidates_df, left_on\u001b[38;5;241m=\u001b[39mvotes_df\u001b[38;5;241m.\u001b[39mcolumns[\u001b[38;5;241m1\u001b[39m], right_on\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCandidateName\u001b[39m\u001b[38;5;124m'\u001b[39m, how\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minner\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     23\u001b[0m \u001b[38;5;66;03m# Step 2: Drop unnecessary columns\u001b[39;00m\n\u001b[0;32m     24\u001b[0m merged_df \u001b[38;5;241m=\u001b[39m merged_df\u001b[38;5;241m.\u001b[39mdrop([\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCandidateName\u001b[39m\u001b[38;5;124m'\u001b[39m], axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\reshape\\merge.py:148\u001b[0m, in \u001b[0;36mmerge\u001b[1;34m(left, right, how, on, left_on, right_on, left_index, right_index, sort, suffixes, copy, indicator, validate)\u001b[0m\n\u001b[0;32m    131\u001b[0m \u001b[38;5;129m@Substitution\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mleft : DataFrame or named Series\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    132\u001b[0m \u001b[38;5;129m@Appender\u001b[39m(_merge_doc, indents\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m    133\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmerge\u001b[39m(\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    146\u001b[0m     validate: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    147\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame:\n\u001b[1;32m--> 148\u001b[0m     op \u001b[38;5;241m=\u001b[39m _MergeOperation(\n\u001b[0;32m    149\u001b[0m         left,\n\u001b[0;32m    150\u001b[0m         right,\n\u001b[0;32m    151\u001b[0m         how\u001b[38;5;241m=\u001b[39mhow,\n\u001b[0;32m    152\u001b[0m         on\u001b[38;5;241m=\u001b[39mon,\n\u001b[0;32m    153\u001b[0m         left_on\u001b[38;5;241m=\u001b[39mleft_on,\n\u001b[0;32m    154\u001b[0m         right_on\u001b[38;5;241m=\u001b[39mright_on,\n\u001b[0;32m    155\u001b[0m         left_index\u001b[38;5;241m=\u001b[39mleft_index,\n\u001b[0;32m    156\u001b[0m         right_index\u001b[38;5;241m=\u001b[39mright_index,\n\u001b[0;32m    157\u001b[0m         sort\u001b[38;5;241m=\u001b[39msort,\n\u001b[0;32m    158\u001b[0m         suffixes\u001b[38;5;241m=\u001b[39msuffixes,\n\u001b[0;32m    159\u001b[0m         indicator\u001b[38;5;241m=\u001b[39mindicator,\n\u001b[0;32m    160\u001b[0m         validate\u001b[38;5;241m=\u001b[39mvalidate,\n\u001b[0;32m    161\u001b[0m     )\n\u001b[0;32m    162\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m op\u001b[38;5;241m.\u001b[39mget_result(copy\u001b[38;5;241m=\u001b[39mcopy)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\reshape\\merge.py:741\u001b[0m, in \u001b[0;36m_MergeOperation.__init__\u001b[1;34m(self, left, right, how, on, left_on, right_on, axis, left_index, right_index, sort, suffixes, indicator, validate)\u001b[0m\n\u001b[0;32m    733\u001b[0m (\n\u001b[0;32m    734\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mleft_join_keys,\n\u001b[0;32m    735\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mright_join_keys,\n\u001b[0;32m    736\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mjoin_names,\n\u001b[0;32m    737\u001b[0m ) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_merge_keys()\n\u001b[0;32m    739\u001b[0m \u001b[38;5;66;03m# validate the merge keys dtypes. We may need to coerce\u001b[39;00m\n\u001b[0;32m    740\u001b[0m \u001b[38;5;66;03m# to avoid incompatible dtypes\u001b[39;00m\n\u001b[1;32m--> 741\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_coerce_merge_keys()\n\u001b[0;32m    743\u001b[0m \u001b[38;5;66;03m# If argument passed to validate,\u001b[39;00m\n\u001b[0;32m    744\u001b[0m \u001b[38;5;66;03m# check if columns specified as unique\u001b[39;00m\n\u001b[0;32m    745\u001b[0m \u001b[38;5;66;03m# are in fact unique.\u001b[39;00m\n\u001b[0;32m    746\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m validate \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\reshape\\merge.py:1401\u001b[0m, in \u001b[0;36m_MergeOperation._maybe_coerce_merge_keys\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1395\u001b[0m     \u001b[38;5;66;03m# unless we are merging non-string-like with string-like\u001b[39;00m\n\u001b[0;32m   1396\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m (\n\u001b[0;32m   1397\u001b[0m         inferred_left \u001b[38;5;129;01min\u001b[39;00m string_types \u001b[38;5;129;01mand\u001b[39;00m inferred_right \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m string_types\n\u001b[0;32m   1398\u001b[0m     ) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[0;32m   1399\u001b[0m         inferred_right \u001b[38;5;129;01min\u001b[39;00m string_types \u001b[38;5;129;01mand\u001b[39;00m inferred_left \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m string_types\n\u001b[0;32m   1400\u001b[0m     ):\n\u001b[1;32m-> 1401\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg)\n\u001b[0;32m   1403\u001b[0m \u001b[38;5;66;03m# datetimelikes must match exactly\u001b[39;00m\n\u001b[0;32m   1404\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m needs_i8_conversion(lk\u001b[38;5;241m.\u001b[39mdtype) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m needs_i8_conversion(rk\u001b[38;5;241m.\u001b[39mdtype):\n",
      "\u001b[1;31mValueError\u001b[0m: You are trying to merge on int64 and object columns. If you wish to proceed you should use pd.concat"
     ]
    }
   ],
   "source": [
    "# Create a dictionary mapping candidate names to their respective parties\n",
    "candidate_party_mapping = dict(zip(df_party['Candidate'], df_party['Party']))\n",
    "\n",
    "# Create a new dataframe containing the total votes for each party in each county\n",
    "df_result = df_votes.copy()\n",
    "for col in df_votes.columns[1:]:\n",
    "    # Map candidate name to party using the created dictionary\n",
    "    party_column = df_votes[col].map(candidate_party_mapping)\n",
    "    \n",
    "    # Group by county and party, summing the votes\n",
    "    df_result[col] = df_votes.groupby(['County', party_column])[col].transform('sum')\n",
    "\n",
    "# Drop duplicate rows (original candidate columns)\n",
    "df_result = df_result.drop(df_votes.columns[1:], axis=1).drop_duplicates()\n",
    "\n",
    "# Reset the index to make 'County' a regular column\n",
    "df_result.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Print the resulting dataframe\n",
    "print(df_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5c0882b-3661-485e-aede-3a4f6beee4e1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
